name: Gradle dify test

on:
  pull_request:
    paths:
      - 'dify/**'
      - '.github/workflows/gradle-dify-test.yml'
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      DIFY_NETWORK: docker_default  # ÊòæÂºèÂÆö‰πâÁΩëÁªúÂêçÁß∞
      OLLAMA_CONTAINER: ollama
      DIFY_VERSION: 1.7.2
      PLUGIN_ID: "langgenius/ollama:0.0.6@f430f3eb959f4863b1e87171544a8fec179441b90deda5693c85f07712d2a68c"

    steps:
      - name: Check marketplace access
        run: |
          curl -sf --max-time 10 "https://marketplace.dify.ai/api/v1/plugins/langgenius/ollama/0.0.6/download" \
            || { echo "::error::Cannot access marketplace URL"; exit 1; }
          echo "Marketplace URL accessible"

      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup version
        run: |
          APP_VERSION=$(grep -oP 'APP_VERSION=\K[^\s]+' gradle.properties || echo "unknown")
          echo "APP_VERSION=$APP_VERSION" >> $GITHUB_ENV
          echo "Using version: $APP_VERSION"

      - name: Setup JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: 'gradle'

      - name: Setup Gradle
        uses: gradle/actions/setup-gradle@v4
        with:
          gradle-version: "8.10.2"

      - name: Clone Dify repository
        run: |
          git clone -b ${{ env.DIFY_VERSION }} --depth 1 \
            https://github.com/langgenius/dify.git tools/dify

      - name: Extract DSL version from Dify
        id: dsl_version
        run: |
          # ËØªÂèñ CURRENT_DSL_VERSION ÂÄº
          DSL_VERSION=$(grep -m1 'CURRENT_DSL_VERSION' tools/dify/api/services/app_dsl_service.py | \
            sed -E 's/.*CURRENT_DSL_VERSION[[:space:]]*=[[:space:]]*"([^"]+)".*/\1/' | \
            tr -d '\r\n' | tr -d '[:space:]')
          
          # È¢ùÂ§ñÈ™åËØÅÔºàÁ°Æ‰øùÊòØÊúâÊïàÁâàÊú¨Âè∑Ôºâ
          if ! [[ "$DSL_VERSION" =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
            echo "::error::Invalid DSL version format: '$DSL_VERSION'"
            exit 1
          fi
          
          echo "‚úÖ Extracted DSL version: $DSL_VERSION"
          
          # ÂÆâÂÖ®ÂÜôÂÖ•ÁéØÂ¢ÉÂèòÈáèÔºàÂÖ≥ÈîÆ‰øÆÂ§çÔºâ
          echo "CURRENT_DSL_VERSION=$DSL_VERSION" | tr -d '\n' >> $GITHUB_ENV

      - name: Start Dify containers
        run: |
          cd tools/dify/docker
          cp .env.example .env
          docker compose up -d
          echo "Waiting for Dify API to be ready..."
          timeout 120 bash -c 'until curl -sSf http://localhost/console/api/init; do sleep 5; done'
          docker compose ps

      - name: Setup Ollama
        run: |
          docker run -d --name ${{ env.OLLAMA_CONTAINER }} -p 11434:11434 \
            --network ${{ env.DIFY_NETWORK }} ollama/ollama
          
          echo "Waiting for Ollama to be ready..."
          timeout 60 bash -c 'until curl -sSf http://localhost:11434/api/tags; do sleep 2; done'
          
          # Verify network connectivity
          docker inspect ${{ env.OLLAMA_CONTAINER }} | grep -q ${{ env.DIFY_NETWORK }} \
            || echo "::warning::Ollama not connected to ${{ env.DIFY_NETWORK }} network"

      - name: Pull Ollama models
        run: |
          docker exec ${{ env.OLLAMA_CONTAINER }} ollama pull bge-m3:latest
          docker exec ${{ env.OLLAMA_CONTAINER }} ollama pull qwen2.5:1.5b

      - name: Initialize Dify
        run: |
          curl -sf -X GET 'http://localhost/console/api/init' \
            -H 'Content-Type: application/json' \
            --retry 5 --retry-delay 5

      - name: Create admin user
        run: |
          curl -sf -X POST 'http://localhost/console/api/setup' \
            -H 'Content-Type: application/json' \
            --data '{"email":"admin@admin.com","name":"admin","password":"admin123456"}' \
            --retry 5 --retry-delay 5

      - name: Get admin token
        id: get_token
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          RESPONSE=$(curl -sf -X POST 'http://localhost/console/api/login' \
            -H 'Content-Type: application/json' \
            --data '{"email":"admin@admin.com","password":"admin123456"}')
          
          TOKEN=$(echo "$RESPONSE" | jq -r '.data.access_token')
          [ -z "$TOKEN" ] && { echo "::error::Failed to get token"; exit 1; }
          echo "admin_token=$TOKEN" >> $GITHUB_OUTPUT

      - name: Install Ollama Plugin
        run: |
          curl -sf -X POST 'http://localhost/console/api/workspaces/current/plugin/install/marketplace' \
            -H "Authorization: Bearer ${{ steps.get_token.outputs.admin_token }}" \
            -H 'Content-Type: application/json' \
            --data '{"plugin_unique_identifiers":["${{ env.PLUGIN_ID }}"]}'

      - name: Verify plugin installation
        run: |
          MAX_ATTEMPTS=15
          for i in $(seq 1 $MAX_ATTEMPTS); do
            if curl -sSf -X GET 'http://localhost/console/api/workspaces/current/plugin/list' \
              -H "Authorization: Bearer ${{ steps.get_token.outputs.admin_token }}" \
              | jq -e '.plugins[] | select(.plugin_id=="langgenius/ollama")' >/dev/null; then
              echo "‚úÖ Plugin installed successfully"
              exit 0
            fi
            echo "‚è≥ Waiting for plugin installation ($i/$MAX_ATTEMPTS)"
            sleep 3
          done
          echo "::error::Plugin installation failed after $MAX_ATTEMPTS attempts"
          exit 1

      - name: Add Ollama models
        run: |
          # Use Docker network name for internal communication
          BASE_URL="http://ollama:11434"
          
          curl -sf -X POST 'http://localhost/console/api/workspaces/current/model-providers/langgenius/ollama/ollama/models' \
            -H "Authorization: Bearer ${{ steps.get_token.outputs.admin_token }}" \
            -H 'Content-Type: application/json' \
            --data '{
              "model": "bge-m3:latest",
              "model_type": "text-embedding",
              "credentials": {
                "mode": "chat",
                "context_size": "4096",
                "max_tokens": "4096",
                "base_url": "'"$BASE_URL"'"
              }
            }'
          
          curl -sf -X POST 'http://localhost/console/api/workspaces/current/model-providers/langgenius/ollama/ollama/models' \
            -H "Authorization: Bearer ${{ steps.get_token.outputs.admin_token }}" \
            -H 'Content-Type: application/json' \
            --data '{
              "model": "qwen2.5:1.5b",
              "model_type": "llm",
              "credentials": {
                "mode": "chat",
                "context_size": "40960",
                "max_tokens": "4096",
                "base_url": "'"$BASE_URL"'"
              }
            }'

      - name: Import test chat app
        run: |
          
           curl 'http://localhost/console/api/apps/imports' \
            -H 'Authorization: Bearer ${{ steps.get_token.outputs.admin_token }}' \
            -H 'content-type: application/json' \
            --data-raw $'{"mode":"yaml-content","yaml_content":"app:\\n  description: \'\'\\n  icon: ü§ñ\\n  icon_background: \'#FFEAD5\'\\n  mode: chat\\n  name: test\\n  use_icon_as_answer_icon: false\\ndependencies:\\n- current_identifier: null\\n  type: marketplace\\n  value:\\n    marketplace_plugin_unique_identifier: ${{ env.PLUGIN_ID }}\\nkind: app\\nmodel_config:\\n  agent_mode:\\n    enabled: false\\n    max_iteration: 5\\n    strategy: function_call\\n    tools: []\\n  annotation_reply:\\n    enabled: false\\n  chat_prompt_config: {}\\n  completion_prompt_config: {}\\n  dataset_configs:\\n    datasets:\\n      datasets: []\\n    reranking_enable: false\\n    retrieval_model: multiple\\n    top_k: 4\\n  dataset_query_variable: \'\'\\n  external_data_tools: []\\n  file_upload:\\n    allowed_file_extensions:\\n    - .JPG\\n    - .JPEG\\n    - .PNG\\n    - .GIF\\n    - .WEBP\\n    - .SVG\\n    - .MP4\\n    - .MOV\\n    - .MPEG\\n    - .MPGA\\n    allowed_file_types: []\\n    allowed_file_upload_methods:\\n    - remote_url\\n    - local_file\\n    enabled: false\\n    image:\\n      detail: high\\n      enabled: false\\n      number_limits: 3\\n      transfer_methods:\\n      - remote_url\\n      - local_file\\n    number_limits: 3\\n  model:\\n    completion_params:\\n      stop: []\\n    mode: chat\\n    name: qwen2.5:1.5b\\n    provider: langgenius/ollama/ollama\\n  more_like_this:\\n    enabled: false\\n  opening_statement: \'\'\\n  pre_prompt: \'\'\\n  prompt_type: simple\\n  retriever_resource:\\n    enabled: true\\n  sensitive_word_avoidance:\\n    configs: []\\n    enabled: false\\n    type: \'\'\\n  speech_to_text:\\n    enabled: false\\n  suggested_questions: []\\n  suggested_questions_after_answer:\\n    enabled: false\\n  text_to_speech:\\n    enabled: false\\n    language: \'\'\\n    voice: \'\'\\n  user_input_form: []\\nversion: ${{ env.CURRENT_DSL_VERSION }}\\n"}'


      - name: Set default models
        run: |
          curl -sf -X POST 'http://localhost/console/api/workspaces/current/default-model' \
            -H "Authorization: Bearer ${{ steps.get_token.outputs.admin_token }}" \
            -H 'Content-Type: application/json' \
            --data '{
              "model_settings": [
                {"model_type": "llm", "provider": "langgenius/ollama/ollama", "model": "qwen2.5:1.5b"},
                {"model_type": "text-embedding", "provider": "langgenius/ollama/ollama", "model": "bge-m3:latest"}
              ]
            }'

      - name: Run Gradle tests
        run: |
          ./gradlew jacocoTestReport --info --no-daemon

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: v${{ env.APP_VERSION }}
          name: GitHub-Actions-${{ github.job }}
